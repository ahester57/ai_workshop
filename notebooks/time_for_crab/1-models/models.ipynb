{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Selection\n",
    "\n",
    "##### *In which we choose the best model to predict the age of a crab.*\n",
    "\n",
    "###### [GitHub Repository](https://github.com/ahester57/ai_workshop/tree/master/notebooks/time_for_crab/1-models)\n",
    "\n",
    "###### [Notebook Viewer](https://nbviewer.jupyter.org/github/ahester57/ai_workshop/blob/master/notebooks/time_for_crab/1-models/models.ipynb)\n",
    "\n",
    "###### [Kaggle Dataset](https://www.kaggle.com/sidhus/crab-age-prediction)\n"
   ],
   "id": "e3e55c8c8889d63e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Constants\n",
   "id": "87b7ac36dfccc35b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T00:11:44.706804Z",
     "start_time": "2024-05-04T00:11:44.703229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "CACHE_FILE = '../cache/crabs.feather'\n",
    "NEXT_CACHE_FILE = '../cache/splitcrabs.feather'\n",
    "NEXT_NOTEBOOK = '../2-features/features.ipynb'\n",
    "MODEL_CHECKPOINT_FILE = '../cache/best_model.keras'\n",
    "\n",
    "PREDICTION_TARGET = 'Age'    # 'Age' is predicted\n",
    "DATASET_COLUMNS = ['Sex_F','Sex_M','Sex_I','Length','Diameter','Height','Weight','Shucked Weight','Viscera Weight','Shell Weight',PREDICTION_TARGET]\n",
    "REQUIRED_COLUMNS = [PREDICTION_TARGET]\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "VALIDATION_SPLIT = 0.2\n"
   ],
   "id": "2771193bbaa184bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import Libraries\n",
   "id": "9c8db9bbea966be5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T00:11:48.202845Z",
     "start_time": "2024-05-04T00:11:48.197848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from notebooks.time_for_crab.mlutils import display_df, plot_training_loss, score_combine, score_comparator, score_model\n",
    "\n",
    "import keras\n",
    "\n",
    "keras_backend = keras.backend.backend()\n",
    "print(f'Keras version: {keras.__version__}')\n",
    "print(f'Keras backend: {keras_backend}')\n",
    "if keras_backend == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(f'TensorFlow version: {tf.__version__}')\n",
    "    print(f'TensorFlow devices: {tf.config.list_physical_devices()}')\n",
    "elif keras_backend == 'torch':\n",
    "    import torch\n",
    "    print(f'Torch version: {torch.__version__}')\n",
    "    print(f'Torch devices: {torch.cuda.get_device_name(torch.cuda.current_device())}')\n",
    "    # torch supports windows-native cuda, but CPU was faster for this task\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('mode.copy_on_write', True)\n"
   ],
   "id": "fb9a82e6844babe5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 3.3.3\n",
      "Keras backend: tensorflow\n",
      "TensorFlow version: 2.16.1\n",
      "TensorFlow devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 995 µs\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Data from Cache\n",
    "\n",
    "In the [previous section](../0-eda/overfit.ipynb), we saved the cleaned data to a cache file. Let's load it back.\n"
   ],
   "id": "3076c85708a8dff8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T00:11:52.887889Z",
     "start_time": "2024-05-04T00:11:52.876119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "crabs = pd.read_feather(CACHE_FILE)\n",
    "display_df(crabs, show_distinct=True)\n"
   ],
   "id": "8b8ce507d07d6927",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (3790, 11)\n",
      "First 5 rows:\n",
      "     Length  Diameter    Height     Weight  Shucked Weight  Viscera Weight  \\\n",
      "0  1.437500  1.174805  0.412598  24.640625       12.335938        5.585938   \n",
      "1  0.887695  0.649902  0.212524   5.402344        2.296875        1.375000   \n",
      "2  1.037109  0.774902  0.250000   7.953125        3.232422        1.601562   \n",
      "3  1.174805  0.887695  0.250000  13.476562        4.750000        2.281250   \n",
      "4  0.887695  0.662598  0.212524   6.902344        3.458984        1.488281   \n",
      "\n",
      "   Shell Weight  Age  Sex_F  Sex_I  Sex_M  \n",
      "0      6.746094    9   True  False  False  \n",
      "1      1.559570    6  False  False   True  \n",
      "2      2.763672    6  False   True  False  \n",
      "3      5.246094   10   True  False  False  \n",
      "4      1.701172    6  False   True  False  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3790 entries, 0 to 3892\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Length          3790 non-null   float16\n",
      " 1   Diameter        3790 non-null   float16\n",
      " 2   Height          3790 non-null   float16\n",
      " 3   Weight          3790 non-null   float16\n",
      " 4   Shucked Weight  3790 non-null   float16\n",
      " 5   Viscera Weight  3790 non-null   float16\n",
      " 6   Shell Weight    3790 non-null   float16\n",
      " 7   Age             3790 non-null   int8   \n",
      " 8   Sex_F           3790 non-null   bool   \n",
      " 9   Sex_I           3790 non-null   bool   \n",
      " 10  Sex_M           3790 non-null   bool   \n",
      "dtypes: bool(3), float16(7), int8(1)\n",
      "memory usage: 96.2 KB\n",
      "Info:\n",
      "None\n",
      "Length distinct values:\n",
      "[1.4375 0.8877 1.037  1.175  1.55   1.3    1.325  1.588  0.9126 0.825 ]\n",
      "Diameter distinct values:\n",
      "[1.175  0.65   0.775  0.8877 0.6626 1.162  1.     1.013  1.25   0.6875]\n",
      "Height distinct values:\n",
      "[0.4126 0.2125 0.25   0.35   0.325  0.375  0.3374 0.1875 0.4375 0.225 ]\n",
      "Weight distinct values:\n",
      "[24.64   5.402  7.953 13.48   6.902 28.66  17.7   23.58  42.22   6.805]\n",
      "Shucked Weight distinct values:\n",
      "[12.336  2.297  3.232  4.75   3.459 13.58   6.094  9.98  20.27   3.062]\n",
      "Viscera Weight distinct values:\n",
      "[5.586 1.375 1.602 2.281 1.488 6.76  5.855 5.3   9.766 1.262]\n",
      "Shell Weight distinct values:\n",
      "[ 6.746  1.56   2.764  5.246  1.701  7.23   4.82   7.16  10.25   2.084]\n",
      "Age distinct values:\n",
      "[ 9  6 10  8 15 13  7 11 12  5]\n",
      "Sex_F distinct values:\n",
      "[ True False]\n",
      "Sex_I distinct values:\n",
      "[False  True]\n",
      "Sex_M distinct values:\n",
      "[False  True]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 7.51 ms\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Split the Data\n",
    "\n",
    "Let's split the data into training and testing sets.\n",
    "\n",
    "It is important to split the data before any data augmentation or normalization to avoid data leakage.  \n",
    "Data leakage lets the model learn from the testing data, which can lead to overfitting.\n",
    "\n",
    "In more general terms, *data leakage* is the phenomenon when the form of a label \"leaks\" into the training feature set.\n",
    "An example this of occurred in 2021 for diagnosing Covid patients. Patients lying down on a bed were more likely to be \"diagnosed\" with Covid.\n",
    "This is because patients confirmed to have Covid were more inclined to bed rest (Huyen, 2022). \n",
    "\n",
    "#### Importance of Data Shuffling\n",
    "\n",
    "Shuffling the data is important to avoid any biases in the data.\n",
    "The order of data shouldn't matter, so shuffling helps mitigate any biases.\n",
    "\n",
    "Shuffling should occur before the test-train split to be most effective.\n",
    "\n",
    "We don't have to worry about time-series data right now\n",
    "(although we could reverse order by 'Age' and call it time-series by new feature 'Crab Birthdate'),\n",
    "but shuffling can have a big impact on the model's performance.\n"
   ],
   "id": "c2205787efb62a9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T00:14:41.966271Z",
     "start_time": "2024-05-04T00:14:41.961054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# split features from target\n",
    "X = crabs.drop([PREDICTION_TARGET], axis=1)\n",
    "y = crabs[PREDICTION_TARGET]\n",
    "\n",
    "# 80% training, 20% testing\n",
    "train_size = int((1. - VALIDATION_SPLIT) * len(X))\n",
    "\n",
    "# shuffle the data\n",
    "random_indices = np.random.default_rng(42).permutation(np.arange(len(X)))\n",
    "\n",
    "# split into train/test sets\n",
    "X_train = X.iloc[random_indices[1:train_size]]\n",
    "X_test = X.drop(X_train.index)\n",
    "y_train = y.iloc[random_indices[1:train_size]]\n",
    "# save the prediction target as a numpy array\n",
    "y_test = np.array(y.drop(y_train.index))\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n"
   ],
   "id": "1bfd70f7fded0074",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (3031, 10)\n",
      "X_test: (759, 10)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 999 µs\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Metrics Used\n",
    "\n",
    "Throughout this notebook, we will use the following metrics to evaluate the regression model:\n",
    "\n",
    "#### Mean Squared Error\n",
    " \n",
    "- The best score is 0.0\n",
    "- Lower is better.\n",
    "\n",
    "#### Mean Absolute Error\n",
    "\n",
    "- The best score is 0.0\n",
    "- Lower is better.\n",
    "- Less sensitive to outliers.\n",
    "\n",
    "#### Explained Variance Score\n",
    "\n",
    "- The best score is 1.0\n",
    "- Lower is worse.\n",
    "\n",
    "#### R2 Score\n",
    "\n",
    "- The best score is 1.0\n",
    "- Lower is worse.\n",
    "\n",
    "#### Max Error\n",
    "\n",
    "- The max error is the very worst score.\n",
    "- Lower is better.\n",
    "- Domain-specific.\n",
    "- 10 years is a lot for a crab.\n"
   ],
   "id": "21801261d7c33c4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Selection\n",
    "\n",
    "So far, we have not done any feature engineering, which can often be the most important part of the process.\n",
    "Some new features could be constructed from our dataset which would call for a different model.\n",
    "Nonetheless, we can start by using all features to set a baseline.\n",
    " \n",
    "We will start with a few simple models to get a baseline accuracy.\n",
    "\n",
    "We will use the following models:\n",
    "- Naive Linear Regression\n",
    "- Linear Regression\n",
    "- Neural Network\n",
    "\n",
    "### Naive Linear Regression\n",
    "\n",
    "The simplest model is a naive linear regression model. It is untrained and will make random guesses.\n"
   ],
   "id": "fdbe372af9fdd9b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T05:31:45.251398Z",
     "start_time": "2024-05-03T05:31:45.227521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# layer: input\n",
    "layer_feature_input = keras.layers.Input(shape=(len(X_train.columns),))\n",
    "\n",
    "# layer: normalizer\n",
    "layer_feature_normalizer = keras.layers.Normalization(axis=-1)\n",
    "layer_feature_normalizer.adapt(np.array(X_train))\n",
    "\n",
    "# layer: output (linear regression)\n",
    "layer_feature_output = keras.layers.Dense(units=1)\n",
    "\n",
    "# architecture:\n",
    "#   input -> normalizer -> linear\n",
    "linear_model = keras.Sequential([\n",
    "    layer_feature_input,\n",
    "    layer_feature_normalizer,\n",
    "    layer_feature_output\n",
    "])\n",
    "\n",
    "linear_model.summary()\n"
   ],
   "id": "1caa9eff20489915",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization_2 (\u001B[38;5;33mNormalization\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m)             │            \u001B[38;5;34m21\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m11\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ normalization_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m32\u001B[0m (132.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (132.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m11\u001B[0m (44.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m21\u001B[0m (88.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> (88.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Configure the Linear Model\n",
    "\n",
    "- **Optimizer**\n",
    "    - Adam: Adaptive Moment Estimation [(Kingma & Ba, 2014)](https://arxiv.org/abs/1412.6980)\n",
    "- **Loss Function**\n",
    "    - Mean Squared Error (MSE)\n",
    "        - This penalizes larger errors more than smaller errors.\n",
    "        - We took out outliers in the data cleaning step, so this should perform better. \n",
    "- **Callbacks**\n",
    "    - Model Checkpoint\n"
   ],
   "id": "f7314ec4298235d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T05:18:57.991661Z",
     "start_time": "2024-05-03T05:18:57.987646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "linear_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "linear_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_CHECKPOINT_FILE.replace('.keras', '_linear.keras'),\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n"
   ],
   "id": "b2f3a4a4d41130d5",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Score the Linear Model (Before Training)\n",
   "id": "a16803057a4986df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T05:18:58.131948Z",
     "start_time": "2024-05-03T05:18:57.993667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "untrained_linear_preds = linear_model.predict(X_test).flatten()\n",
    "# Utility functions imported from mlutils.py\n",
    "untrained_linear_scores_df = score_model(untrained_linear_preds, y_test, index='untrained_linear')\n",
    "# Add it to the leaderboard\n",
    "leaderboard_df = score_combine(pd.DataFrame(), untrained_linear_scores_df)\n",
    "leaderboard_df.head()\n"
   ],
   "id": "68d7d837260ed64c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 510us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  mean_squared_error  mean_absolute_error  \\\n",
       "untrained_linear          109.841179             9.744074   \n",
       "\n",
       "                  explained_variance_score   r2_score  max_error  \n",
       "untrained_linear                  -6.07472 -51.029983  22.334776  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>explained_variance_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>untrained_linear</th>\n",
       "      <td>109.841179</td>\n",
       "      <td>9.744074</td>\n",
       "      <td>-6.07472</td>\n",
       "      <td>-51.029983</td>\n",
       "      <td>22.334776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train the Linear Model\n",
   "id": "cad9b09132c52728"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T05:19:06.615362Z",
     "start_time": "2024-05-03T05:18:58.132953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "feature_rich_history = linear_model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=0,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    callbacks=[linear_checkpoint]\n",
    ")\n"
   ],
   "id": "23aa4c9a92482821",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.45 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Score the Linear Model\n",
   "id": "940fde78a8e39fad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T05:19:06.727296Z",
     "start_time": "2024-05-03T05:19:06.615362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "linear_preds = linear_model.predict(X_test).flatten()\n",
    "linear_scores_df = score_model(linear_preds, y_test, index='linear')\n",
    "# Add it to the leaderboard\n",
    "leaderboard_df = score_combine(leaderboard_df, linear_scores_df)\n",
    "leaderboard_df.head()\n"
   ],
   "id": "41534c47873e938e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m119/119\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 395us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  mean_squared_error  mean_absolute_error  \\\n",
       "untrained_linear          109.841179             9.744074   \n",
       "linear                      6.956643             1.916560   \n",
       "\n",
       "                  explained_variance_score   r2_score  max_error  \n",
       "untrained_linear                 -6.074720 -51.029983  22.334776  \n",
       "linear                           -0.097092  -0.833891  11.443429  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>explained_variance_score</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>untrained_linear</th>\n",
       "      <td>109.841179</td>\n",
       "      <td>9.744074</td>\n",
       "      <td>-6.074720</td>\n",
       "      <td>-51.029983</td>\n",
       "      <td>22.334776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>6.956643</td>\n",
       "      <td>1.916560</td>\n",
       "      <td>-0.097092</td>\n",
       "      <td>-0.833891</td>\n",
       "      <td>11.443429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Neural Network Model\n",
    "\n",
    "#### Neural Network Architecture\n",
    "\n",
    "We will start with a simple neural network with a few layers.\n"
   ],
   "id": "e9d0e6051b40d745"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T00:19:25.778730Z",
     "start_time": "2024-05-04T00:19:25.725156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# layer: input - reused from linear model\n",
    "# layer: normalizer - reused from linear model\n",
    "\n",
    "# layer(s): hidden - new for this model\n",
    "layer_hidden_relu_list = keras.layers.Dense(units=64, activation='relu')\\\n",
    "    , keras.layers.Dense(units=32, activation='relu')\\\n",
    "    , keras.layers.Dense(units=16, activation='relu')\\\n",
    "    , keras.layers.Dense(units=8, activation='relu')\n",
    "\n",
    "# layer: output - reused from linear model\n",
    "\n",
    "# architecture:\n",
    "#   input -> normalizer -> hidden(s) -> dense\n",
    "deep_modal = keras.Sequential([\n",
    "    layer_feature_input,\n",
    "    layer_feature_normalizer,\n",
    "    *layer_hidden_relu_list,\n",
    "    layer_feature_output\n",
    "])\n",
    "\n",
    "deep_modal.summary()\n"
   ],
   "id": "c33ca3e38d695949",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_feature_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m<timed exec>:15\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'layer_feature_input' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Configure the Neural Network Model\n",
    "\n",
    "- **Optimizer**\n",
    "    - Adam: Adaptive Moment Estimation [(Kingma & Ba, 2014)](https://arxiv.org/abs/1412.6980)\n",
    "- **Loss Function**\n",
    "    - Mean Squared Error (MSE)\n",
    "        - This penalizes larger errors more than smaller errors.\n",
    "        - We took out outliers in the data cleaning step, so this should perform better. \n",
    "- **Callbacks**\n",
    "    - Model Checkpoint\n"
   ],
   "id": "19c9ac9a9089a323"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model Accuray Baseline\n",
    "\n",
    "| Model | Acc. on Training Set | Acc. on Validation Set |\n",
    "| --- | --- | --- |\n",
    "| Random baseline classifier | 0% | 0% |\n",
    "| Logistic regression model | 0% | 0% |\n",
    "| Neural network model (64-32-16-8-1) | 0% | 0% |\n",
    "| Neural network model (32-16-8-1) | 0% | 0% |\n",
    "| Neural network model (16-8-1) | 0% | 0% |\n",
    "| Neural network model (8-1) | 0% | 0% |\n",
    "| Neural network model (4-1) | 0% | 0% |\n",
    "| Neural network model (2-1) | 0% | 0% |\n"
   ],
   "id": "ca9aba97af93d34e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save the Data\n",
    "\n",
    "So we can pick this back up on the [next step](../2-features/features.ipynb).\n"
   ],
   "id": "65ebc4ddaa5840b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T05:19:06.735293Z",
     "start_time": "2024-05-03T05:19:06.728305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# save the training and test data separately\n",
    "pd.concat([X_train, y_train], axis=1, join='outer').to_feather(NEXT_CACHE_FILE)\n",
    "pd.concat([X_test, y_test], axis=1, join='outer').to_feather(NEXT_CACHE_FILE.replace('.feather', '_test.feather'))\n"
   ],
   "id": "ac5efd3053fb1d4e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Onwards to Feature Engineering\n",
    "\n",
    "See the [next section](../2-features/features.ipynb) for feature engineering.\n",
    "\n",
    "[`<html link>`](https://nbviewer.org/github/ahester57/ai_workshop/blob/master/notebooks/time_for_crab/2-features/features.ipynb) for feature reduction.\n"
   ],
   "id": "d1bb52a48f355b13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ai",
   "language": "python",
   "name": "venv-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
