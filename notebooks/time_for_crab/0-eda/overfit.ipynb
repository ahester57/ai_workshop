{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Overfitting Crab Age\n",
    "\n",
    "*In which we practice one thing so much that we get worse at everything else.*\n"
   ],
   "id": "1746b7ece4698e11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define Constants\n",
   "id": "31f0958c3ed965e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CACHE_FILE = '../cache/crabs.feather'\n",
    "NEXT_NOTEBOOK = '../1-models/models.ipynb'\n",
    "\n",
    "PREDICTION_TARGET = 'Age'    # 'Age' is predicted\n",
    "DATASET_COLUMNS = ['Sex_F','Sex_M','Sex_I','Length','Diameter','Height','Weight','Shucked Weight','Viscera Weight','Shell Weight',PREDICTION_TARGET]\n",
    "REQUIRED_COLUMNS = [PREDICTION_TARGET]\n",
    "\n",
    "MODEL_CHECKPOINT_FILE = '../cache/overfit_model.weights.h5'\n"
   ],
   "id": "d91e638e9b152a8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Import Libraries\n",
    "\n",
    "PyTorch supports windows-native CUDA, but TensorFlow on CPU was faster for this task.\n"
   ],
   "id": "8dcd9933ae377e9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from notebooks.time_for_crab.mlutils import display_df, plot_training_loss, score_combine, score_comparator, score_model\n",
    "\n",
    "import keras\n",
    "\n",
    "keras_backend = keras.backend.backend()\n",
    "print(f'Keras version: {keras.__version__}')\n",
    "print(f'Keras backend: {keras_backend}')\n",
    "if keras_backend == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    print(f'TensorFlow version: {tf.__version__}')\n",
    "    print(f'TensorFlow devices: {tf.config.list_physical_devices()}')\n",
    "elif keras_backend == 'torch':\n",
    "    import torch\n",
    "    print(f'Torch version: {torch.__version__}')\n",
    "    print(f'Torch devices: {torch.cuda.get_device_name(torch.cuda.current_device())}')\n",
    "    # torch supports windows-native cuda, but CPU was faster for this task\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('mode.copy_on_write', True)\n"
   ],
   "id": "c09927ea9dc6dbfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Data from Cache\n",
    "\n",
    "In the [previous section](../0-eda/eda.ipynb), we saved the cleaned data to a cache file. Let's load it back.\n"
   ],
   "id": "15713cbd53904fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "crabs = pd.read_feather(CACHE_FILE)\n",
    "display_df(crabs)\n"
   ],
   "id": "a0735452b18b2cff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Overfitting Crab Age\n",
    "\n",
    "![Large mud crab measure](https://upload.wikimedia.org/wikipedia/commons/thumb/6/65/CSIRO_ScienceImage_10696_Mud_crabs_are_caught_measured_tagged_and_released_as_part_of_the_research_into_the_effectiveness_of_green_zones_in_Moreton_Bay.jpg/1920px-CSIRO_ScienceImage_10696_Mud_crabs_are_caught_measured_tagged_and_released_as_part_of_the_research_into_the_effectiveness_of_green_zones_in_Moreton_Bay.jpg)\n"
   ],
   "id": "d7a2d25f6b2bac4f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Overfitting Goals and Methods \n",
    "\n",
    "The goal here is to show how complex of a model it will take to overfit the data.\n",
    "\n",
    "We will use the following methods to overfit the data:\n",
    "\n",
    "1. **Linear Regression**: Gradually increase the complexity of a linear regression model.\n",
    "2. **Model Stacking**: Stack models to overfit the model.\n",
    "\n",
    "I am following the TensorFlow tutorial on [Linear Regression](https://www.tensorflow.org/tutorials/keras/regression#linear_regression_with_one_variable) to build the linear regression model.\n",
    "\n",
    "> There are two steps in your single-variable linear regression model:  \n",
    ">    1. Normalize the 'Horsepower' input features using the tf.keras.layers.Normalization preprocessing layer.\n",
    ">    2. Apply a linear transformation ($y = mx + b$) to produce 1 output using a linear layer (tf.keras.layers.Dense).\n",
    "\n",
    "Instead of 'Horsepower', we'll use 'Shell Weight' as our regression variable.\n"
   ],
   "id": "103d8d58c482834a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build the Shell Weight Model\n",
    "\n",
    "This is a simple linear regression model that predicts the age of a crab based on its shell weight. It remains untrained.\n"
   ],
   "id": "3fc8f94b175e2599"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Layer: Input Layer\n",
    "\n",
    "This defines the shape of our input to the model.\n"
   ],
   "id": "667c01d583edcd44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shell_weight_input = keras.layers.Input(shape=(1,))\n",
   "id": "a8ec3f680458fa79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Layer: Shell Weight Normalizer Layer\n",
    "\n",
    "This is a quick and easy way to normalize our input data.\n",
    "\n",
    "***Note**: In later steps, we will use a custom normalizer to show how it's done.*\n"
   ],
   "id": "77a7fea72e842822"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shell_weight = np.array(crabs['Shell Weight'])\n",
    "shell_weight_normalizer = keras.layers.Normalization(axis=None)\n",
    "shell_weight_normalizer.adapt(shell_weight)\n"
   ],
   "id": "c467ccadeac5ff97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Layer: Dense Layer\n",
    "\n",
    "This is the layer that will perform the linear regression.\n"
   ],
   "id": "a2a7e07544c55125"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shell_weight_dense = keras.layers.Dense(units=1)\n",
   "id": "2d8cb6136c4b95dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Architecture: Bringing it All Together\n",
    "\n",
    "Now we'll put all the layers together to create the model. It is still going to be untrained.\n"
   ],
   "id": "4b180523244a95f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shell_weight_model = keras.Sequential([\n",
    "    shell_weight_input,\n",
    "    shell_weight_normalizer,\n",
    "    shell_weight_dense\n",
    "])\n",
    "\n",
    "shell_weight_model.summary()\n"
   ],
   "id": "79a4cab8cabf0d8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predictions: Pre-Training (For Science)\n",
    "\n",
    "We don't expect good results here. This is just to get a baseline.\n",
    "\n"
   ],
   "id": "8564679ccb01799f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shell_weight_target = np.array(crabs[PREDICTION_TARGET])\n",
    "shell_weight_preds = shell_weight_model.predict(shell_weight).flatten()\n",
    "\n",
    "print(shell_weight_target)\n",
    "print(shell_weight_preds)\n"
   ],
   "id": "cc889757ef07bdb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Scores: Naive Model\n",
    "\n",
    "Throughout this notebook, we will use the following metrics to evaluate the regression model:\n",
    "\n",
    "- **Mean Squared Error**\n",
    "    - The best possible score is 0.0, lower values are better.\n",
    "- **Mean Absolute Error**\n",
    "    - The best possible score is 0.0, lower values are better. Less sensitive to outliers.\n",
    "- **Explained Variance Score**\n",
    "    - The best possible score is 1.0, lower values are worse.\n",
    "- **R2 Score**\n",
    "    - The best possible score is 1.0, lower values are worse.\n",
    "- **Max Error**\n",
    "    - The max error is the worst possible score. Domain-specific. 10 years is a lot for a crab.\n",
    " "
   ],
   "id": "fa089ca135e055ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "naive_scores_df = score_model(shell_weight_preds, shell_weight_target, index='naive')\n",
    "naive_scores_df.head()\n"
   ],
   "id": "b4f4a28001054440"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Observations: Naive Model\n",
    "\n",
    "As expected, the untrained scores are terrible.\n"
   ],
   "id": "5396e544d9adc24b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prepare the Shell Weight Model\n",
    "\n",
    "Now it's finally time to get learning!\n",
    "\n",
    "#### Compile\n",
    "\n",
    "We will use the mean squared error as the loss function and the Adam optimizer.\n"
   ],
   "id": "e7c16a697c09fb5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shell_weight_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_squared_error'\n",
    ")\n"
   ],
   "id": "cac425ecc8a7402f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Checkpoint the Shell Weight Model\n",
    "\n",
    "We want to save the model for later reference.\n"
   ],
   "id": "32262eefe525541e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shell_weight_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_CHECKPOINT_FILE.replace('overfit', 'shell_weight'),\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n"
   ],
   "id": "cc8dc7bcb73cc47a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train the Shell Weight Model\n",
    "\n",
    "Let's train for 100 epochs.\n"
   ],
   "id": "d28efb17d244e963"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "history = shell_weight_model.fit(\n",
    "    x=crabs['Shell Weight'],\n",
    "    y=crabs[PREDICTION_TARGET],\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[shell_weight_checkpoint]\n",
    ")\n"
   ],
   "id": "78f0b2147c71d4e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot Training History\n",
   "id": "e4ef42da9fcfbac6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df['epoch'] = history.epoch\n",
    "history_df.tail()\n"
   ],
   "id": "663f418d9ba1292e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot Loss History\n",
   "id": "3e9bedc5511eef8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "plot_training_loss(history)\n"
   ],
   "id": "eeda836dcb2696ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### View the Line of Best Fit",
   "id": "f8419636ff2d7dc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x = np.linspace(crabs['Age'].min(), crabs['Age'].max(), 100)\n",
    "y = shell_weight_model.predict(x).flatten()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(crabs['Shell Weight'], crabs['Age'], label='Data')\n",
    "plt.plot(x, y, color='red', label='Best Fit')\n",
    "plt.xlabel('Shell Weight')\n",
    "plt.ylabel('Age')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "cc0b797b89f7f28e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predictions: Shell Weight Model\n",
    "\n",
    "Now that we've trained the model, let's see how it performs.\n",
    "\n",
    "We are hoping for almost 100% accuracy or zero error to achieve overfitting. However, we are not expecting this to happen just yet.\n",
    "\n",
    "We have only trained the model on one feature, 'Shell Weight'. It is unlikely that just one feature (*except maybe the target itself*) will be able to overfit the data.\n"
   ],
   "id": "f1150b6dbc8c2b13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shell_weight_target = np.array(crabs[PREDICTION_TARGET])\n",
    "shell_weight_preds = shell_weight_model.predict(shell_weight).flatten()\n",
    "\n",
    "print(shell_weight_target)\n",
    "print(shell_weight_preds)\n"
   ],
   "id": "f169127ea8a55811"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Scores: Shell Weight Model\n",
    "\n",
    "Reminder of our metrics:\n",
    "\n",
    "- **Mean Squared Error**\n",
    "    - The best possible score is 0.0, lower values are better.\n",
    "- **Mean Absolute Error**\n",
    "    - The best possible score is 0.0, lower values are better. Less sensitive to outliers.\n",
    "- **Explained Variance Score**\n",
    "    - The best possible score is 1.0, lower values are worse.\n",
    "- **R2 Score**\n",
    "    - The best possible score is 1.0, lower values are worse.\n",
    "- **Max Error**\n",
    "    - The max error is the worst possible score. Domain-specific. 10 years is a lot for a crab.\n",
    " "
   ],
   "id": "4ed0bb661d097024"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "shell_weight_scores_df = score_model(shell_weight_preds, shell_weight_target, index='shell_weight')\n",
    "\n",
    "leaderboard_df = score_combine(naive_scores_df, shell_weight_scores_df)\n",
    "\n",
    "leaderboard_df.head()\n"
   ],
   "id": "fea8701f9130ca19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Comparison: Naive vs Shell Weight",
   "id": "baef54d04e8351c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "leaderboard_df.plot(kind='bar', title='Naive vs Trained Model Scores', figsize=(20, 10))\n",
   "id": "6188aa0374368c36"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Score-by-Score Comparison: Naive vs Shell Weight\n",
    "\n",
    "Break down the bar charts into one for each metric.\n"
   ],
   "id": "ad148c9b6f526eeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "score_comparator(naive_scores_df, shell_weight_scores_df, train_label='Naive', test_label='Trained')\n"
   ],
   "id": "27518459572d03fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observations: Shell Weight Model\n",
    "\n",
    "The scores are much better after training! But not even close to overfitting the data.\n",
    "\n",
    "Shell Weight alone must not be a good predictor of crab age.\n"
   ],
   "id": "618bd391c178461a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build the Feature-Rich Model\n",
    "\n",
    "Moving on to [linear regression with multiple variables](https://www.tensorflow.org/tutorials/keras/regression#linear_regression_with_multiple_inputs).\n",
    "\n",
    "In order to overfit, we're going to need to give the model more features from the dataset.\n",
    "\n",
    "Shell Weight alone is not going to cut it. We need to increase the complexity to a point where the model is just memorizing the training data.\n",
    "\n",
    "We'll increase the input dimensions to the number of crab features. We exclude the target column from this count.\n",
    "\n"
   ],
   "id": "236a3a6204f3ecb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# layer: input\n",
    "overfit_input = keras.layers.Input(shape=(len(crabs.columns) - 1,))\n",
    "\n",
    "# layer: normalizer\n",
    "overfit_normalizer = keras.layers.Normalization(axis=-1)\n",
    "overfit_normalizer.adapt(np.array(crabs.drop(columns=[PREDICTION_TARGET])))\n",
    "\n",
    "# layer: dense (linear regression)\n",
    "overfit_dense = keras.layers.Dense(units=1)\n",
    "\n",
    "# architecture:\n",
    "#   input -> normalizer -> dense\n",
    "overfit_model = keras.Sequential([\n",
    "    overfit_input,\n",
    "    overfit_normalizer,\n",
    "    overfit_dense\n",
    "])\n",
    "\n",
    "overfit_model.summary()\n"
   ],
   "id": "c3283e6ffc99d7ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prepare the Feature-Rich Model\n",
    "\n",
    "#### Compile\n",
    "\n",
    "We will use the mean squared error as the loss function and the Adam optimizer.\n"
   ],
   "id": "e79da6d9b7ed2d7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "overfit_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_squared_error'\n",
    ")\n"
   ],
   "id": "24405ceeedda2db9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Checkpoint the Feature-Rich Model\n",
    "\n",
    "We want to save the model for later reference.\n"
   ],
   "id": "2bbcf100d672831e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "overfit_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_CHECKPOINT_FILE,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n"
   ],
   "id": "577411cf04fcad9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train the Feature-Rich Model\n",
    "\n",
    "Let's train for 100 epochs."
   ],
   "id": "b105a29367d84024"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%time\n",
    "history = overfit_model.fit(\n",
    "    x=crabs.drop(columns=[PREDICTION_TARGET]),\n",
    "    y=crabs[PREDICTION_TARGET],\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[overfit_checkpoint]\n",
    ")\n"
   ],
   "id": "45715f5d2f1f730f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot the Loss History",
   "id": "2118c490af4c6d4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "plot_training_loss(history)\n"
   ],
   "id": "cd55bdb45663bb5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predictions: Feature-Rich Model\n",
    "\n",
    "We are hoping it did *too* well.\n"
   ],
   "id": "8d1f6ccd03fac91d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "overfit_target = np.array(crabs[PREDICTION_TARGET])\n",
    "overfit_preds = overfit_model.predict(crabs.drop(columns=[PREDICTION_TARGET])).flatten()\n",
    "\n",
    "print(overfit_target)\n",
    "print(overfit_preds)\n"
   ],
   "id": "65ab10de6de31e64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Scores: Feature-Rich Model\n",
    "\n",
    "Metrics used:\n",
    "\n",
    "- **Mean Squared Error**\n",
    "    - The best possible score is 0.0, lower values are better.\n",
    "- **Mean Absolute Error**\n",
    "    - The best possible score is 0.0, lower values are better. Less sensitive to outliers.\n",
    "- **Explained Variance Score**\n",
    "    - The best possible score is 1.0, lower values are worse.\n",
    "- **R2 Score**\n",
    "    - The best possible score is 1.0, lower values are worse.\n",
    "- **Max Error**\n",
    "    - The max error is the worst possible score. Domain-specific. 10 years is a lot for a crab.\n"
   ],
   "id": "9a59e9a6841563e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "overfit_scores_df = score_model(overfit_preds, overfit_target, index='overfit')\n",
    "\n",
    "leaderboard_df = score_combine(leaderboard_df, overfit_scores_df)\n",
    "\n",
    "leaderboard_df.head()\n"
   ],
   "id": "91a476a017a5ecfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Comparison: Shell Weight vs Feature-Rich\n",
    "\n",
    "We'll see if this feature-rich model is any better than the Shell Weight model.\n"
   ],
   "id": "42af32f72abff20f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "leaderboard_df.drop('naive').plot(kind='bar', title='Shell Weight vs All Feature Model Scores', figsize=(20, 10))\n",
   "id": "378abafe5a2a2c15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Score-by-Score Comparison: Shell Weight vs Feature-Rich\n",
    "\n",
    "Break down the bar charts into one for each metric.\n"
   ],
   "id": "8a4baa2ad7ea27fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Utility functions imported from mlutils.py\n",
    "score_comparator(shell_weight_scores_df, overfit_scores_df, train_label='Shell Weight', test_label='Feature-Rich')\n"
   ],
   "id": "771e26c9ed27537d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Observations: Feature-Rich Model\n",
    "\n",
    "The scores are better than the Shell Weight model, but not by much. We must go deeper!\n"
   ],
   "id": "19fca4bf60ca8c0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Don't Save this Data\n",
    "\n",
    "We don't want our over-trained model to leak into the [next step](../1-models/models.ipynb).\n"
   ],
   "id": "5ba016cb1835a679"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Onwards to Model Selection\n",
    "\n",
    "See the [next section](../1-models/models.ipynb) for model selection.\n"
   ],
   "id": "91239f75397ebd5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "get_ipython().run_line_magic('notebook', NEXT_NOTEBOOK)\n",
   "id": "381cd98d3688dfc2"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
