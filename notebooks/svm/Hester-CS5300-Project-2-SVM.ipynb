{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9f1403b-3bf5-4004-9e06-238799fcf5c5",
   "metadata": {},
   "source": [
    "## Coronavirus Prediction using SVM\n",
    "\n",
    "Address the following questions:\n",
    "\n",
    "- What the problem is about?\n",
    "- What prior knowledge the agent has, which influences the model it builds?\n",
    "- What data and feedback on the data is available?\n",
    "- What is the size of the data?\n",
    "- How to load a dataset that has non-numbers?\n",
    "- What are the features (predictors and target variable) in the data?\n",
    "- Are there any missing data? If so, how to handle them?\n",
    "- what the data is saying?\n",
    "- what kind of model(learning agent) is suited for the data?\n",
    "- are all predictors necessary for the agent?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5796c82e-1694-4af9-9463-04339995d1b3",
   "metadata": {},
   "source": "## Import Libraries\n"
  },
  {
   "cell_type": "code",
   "id": "23315123-6992-465a-b4a0-b99ca9d94907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:15:21.380642Z",
     "start_time": "2024-04-28T22:15:20.248739Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "try:\n",
    "    # for visual mode. `pip install -e .[visual]`\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    %matplotlib inline\n",
    "    import seaborn as sns\n",
    "except ModuleNotFoundError:\n",
    "    plt = None\n",
    "    sns = None"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8e5785ee-c15a-4a4b-9105-173df0bc70b8",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "id": "eba12f9a-cb57-4dde-9e57-d21f287f8bbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:15:21.384016Z",
     "start_time": "2024-04-28T22:15:21.381648Z"
    }
   },
   "source": [
    "TARGET_LABEL = 'Corona'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9362ea08-57eb-404c-8f68-2aea66d02f07",
   "metadata": {},
   "source": [
    "## DataFrame Display Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "0ed45bcc-7cbc-45df-820d-3ab6581d574d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:15:21.389716Z",
     "start_time": "2024-04-28T22:15:21.384016Z"
    }
   },
   "source": [
    "def display_df(df:pd.DataFrame, show_missing:bool=True, show_info:bool=False) -> None:\n",
    "    \"\"\"Display the DataFrame.\n",
    "    \n",
    "    :param df: The data.\n",
    "    :type df: pd.DataFrame\n",
    "    :param show_missing: Whether to show missing data counts.\n",
    "    :type show_missing: bool\n",
    "    :param show_info: Whether to show info on the data.\n",
    "    :type show_info: bool\n",
    "    \"\"\"\n",
    "    print(f'DataFrame shape: {df.shape}')\n",
    "    print(f'First 5 rows:\\n{df.head()}') # preview the first 5 rows\n",
    "    if show_missing:\n",
    "        # find any non-numeric data\n",
    "        print(f'Missing values:\\n{df.isna().sum()}')\n",
    "    if show_info:\n",
    "        print(f'Info:\\n{df.info()}')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "5230deef-65ef-42ab-800f-56b8b395efc3",
   "metadata": {},
   "source": [
    "## Dataset Cleanup\n",
    "- Remove rows:\n",
    "    - missing any of the symptoms.\n",
    "    - diagnosis of 'other'"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e57adc7-f043-42c7-994d-9b7374b00c50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:15:21.393925Z",
     "start_time": "2024-04-28T22:15:21.390722Z"
    }
   },
   "source": [
    "def data_disposal(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean-up the DataFrame.\n",
    "\n",
    "    Remove rows:\n",
    "        - missing any of the symptoms\n",
    "        - diagnosis of 'other'\n",
    "    \n",
    "    :param df: The data.\n",
    "    :type df: pd.DataFrame\n",
    "    :return: The data without disposals.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # remove rows missing too many values\n",
    "    required_fields=[TARGET_LABEL, 'Cough_symptoms', 'Fever', 'Sore_throat', 'Shortness_of_breath', 'Headache']\n",
    "    print(f'Dropping the rows missing required columns: {required_fields}')\n",
    "    df = df.dropna(subset=required_fields)\n",
    "    # weird find, get rid of rows where diagnosis is 'other'\n",
    "    df = df[df[TARGET_LABEL] != 'other']\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "496f7ac8-661c-43da-89ce-be4ae5ed53d6",
   "metadata": {},
   "source": [
    "## Datatype Conversions\n",
    "- Convert bools to `0|1`.\n",
    "- Fill nulls for typically-binary variables with 0.5.\n",
    "- Scale 'Known_contact' with best-guess weights. Could use SA to fine-tune.\n",
    "- convert 'Test_date' to unix epoch"
   ]
  },
  {
   "cell_type": "code",
   "id": "199616df-22b9-4e2d-9bb0-9b9714d75dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:15:21.398519Z",
     "start_time": "2024-04-28T22:15:21.393925Z"
    }
   },
   "source": [
    "def data_conversions(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert type in the DataFrame.\n",
    "\n",
    "    Update values:\n",
    "        - Convert bools to `0|1`.\n",
    "        - Fill nulls for typically-binary variables with 0.5.\n",
    "        - Scale 'Known_contact' with best-guess weights. Could use SA to fine-tune.\n",
    "        - convert 'Test_date' to unix epoch\n",
    "\n",
    "    :param df: The data.\n",
    "    :type df: pd.DataFrame\n",
    "    :return: The data without conversions.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # check for \"weird\" data\n",
    "    weird_check_cols = ['Test_date', TARGET_LABEL, 'Age_60_above', 'Sex', 'Known_contact']\n",
    "    for col in weird_check_cols:\n",
    "        print(f'Column \"{col}\" distinct values:\\t{df[col].unique()}')\n",
    "    # filter bools\n",
    "    df = df.replace(to_replace={\n",
    "        False: 0, True: 1,\n",
    "        'negative': 0, 'positive': 1,\n",
    "        'No': 0, 'Yes': 1,\n",
    "        'male': 0, 'female': 1\n",
    "    })\n",
    "    # weird finds, fill null values for typically-binary variables with 0.5\n",
    "    df = df.fillna({\n",
    "        'Age_60_above': 0.5,\n",
    "        'Sex': 0.5\n",
    "    })\n",
    "    # weird find, scale 'Known_contact' with best-guess weights. Could use SA to fine-tune.\n",
    "    df = df.replace(to_replace={'Known_contact': {'Abroad': 1, 'Contact with confirmed': 0.6, 'Other': 0}})\n",
    "    # last weird find, convert 'Test_date' to unix epoch\n",
    "    df['Test_date'] = pd.to_datetime(df['Test_date'], format='%d-%m-%Y').astype('int64') / 10**9\n",
    "    # finally infer objects\n",
    "    return df.infer_objects()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "94e2d99a-4ba6-45fd-ba87-8240f713ded9",
   "metadata": {},
   "source": [
    "## Open the Dataset File\n",
    "\n",
    "Upon first loading the dataset, this warning is output:\n",
    "\n",
    "```\n",
    "DtypeWarning: Columns (2,3,4,5,6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
    "```\n",
    "Which means we'll have 6 columns to clean up.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f77f4a35-913d-4678-b3c6-336d579bea73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T22:15:21.888072Z",
     "start_time": "2024-04-28T22:15:21.399527Z"
    }
   },
   "source": [
    "pd.set_option('mode.copy_on_write', True)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "try:\n",
    "    df = pd.read_csv('./corona-1.csv')\n",
    "except FileNotFoundError:\n",
    "    print(f'Could not open file for read: {dataset_filename}')\n",
    "display_df(df)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 4\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m----> 4\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./corona-1.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\dev\\.venv-ai\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\dev\\.venv-ai\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n",
      "File \u001B[1;32m~\\dev\\.venv-ai\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\dev\\.venv-ai\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\dev\\.venv-ai\\Lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    871\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m     \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m     handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m        \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './corona-1.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m     df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./corona-1.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCould not open file for read: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mdataset_filename\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m display_df(df)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataset_filename' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "83293609-54c0-4a10-8eb7-532ac45135b3",
   "metadata": {},
   "source": [
    "## Remove Bad Data\n",
    "- Remove data:\n",
    "    - missing any of the symptoms.\n",
    "    - diagnosis of 'other'\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "51b8b8cb-f0ba-45c4-9b08-717d22d830d3",
   "metadata": {},
   "source": [
    "# Remove bad data\n",
    "df = data_disposal(df)\n",
    "display_df(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "411339df-7a7e-4bb3-90b5-61ac27878c86",
   "metadata": {},
   "source": [
    "## Numerify Remaining Data\n",
    "- Convert bools to `0|1`.\n",
    "- Fill nulls for typically-binary variables with 0.5.\n",
    "- Scale 'Known_contact' with best-guess weights. Could use SA to fine-tune.\n",
    "- convert 'Test_date' to unix epoch"
   ]
  },
  {
   "cell_type": "code",
   "id": "331d2431-a363-4834-ab06-6da4aacd82ec",
   "metadata": {},
   "source": [
    "# Numerify some data\n",
    "df = data_conversions(df)\n",
    "display_df(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "43932eb8-8969-4793-a315-44832d4d3561",
   "metadata": {},
   "source": [
    "## Shuffle the Rows\n",
    "\n",
    "When you shuffle rows, there's a trade-off.\n",
    "\n",
    "- Better prepared for unseen data.\n",
    "- Lose reproducibility of model-training."
   ]
  },
  {
   "cell_type": "code",
   "id": "d01f3f4d-2d8c-4112-bc0f-5933bcaa943d",
   "metadata": {},
   "source": [
    "df = df.sample(frac=1)\n",
    "display_df(df, show_info=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50e10326-d1c9-49d8-8e4f-aa5cd8bd43a4",
   "metadata": {},
   "source": [
    "## Split into Training/Validation Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "749d346c-0040-4234-88da-a52427521d61",
   "metadata": {},
   "source": [
    "# Split into Training/Validation sets\n",
    "X = df.drop([TARGET_LABEL], axis=1)\n",
    "y = df[TARGET_LABEL]\n",
    "# drop id. it would poison the data.\n",
    "X = X.drop(['Ind_ID'], axis=1)\n",
    "# after some thought, I will remove the 'Test_date' from training set.\n",
    "X = X.drop(['Test_date'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8fd96cd-0861-4d2c-aff2-e559adcec97f",
   "metadata": {},
   "source": [
    "## Show the Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "id": "29810356-aea9-4a45-99ed-30b158f6185c",
   "metadata": {},
   "source": [
    "if plt is not None:\n",
    "    sns.set()\n",
    "    plt.figure(figsize = (11,8))\n",
    "    plt.title('Correlation Graph')\n",
    "    # Plotting the heatmap to check the correlation between the Target Label and other features\n",
    "    sns.heatmap(df.corr()[[TARGET_LABEL]].sort_values(by=TARGET_LABEL, ascending=False), vmin=-1, vmax=1, annot=True, cmap='GnBu')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53e62c00-9ac4-44a0-883a-47a873d72e52",
   "metadata": {},
   "source": [
    "## Create and Train the Model\n",
    "This takes a couple minutes."
   ]
  },
  {
   "cell_type": "code",
   "id": "f05f826b-8347-42f9-8bbc-96a85840a63d",
   "metadata": {},
   "source": [
    "# create and train the model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1480ce66-b6d9-4a4a-9c85-b95390131da4",
   "metadata": {},
   "source": [
    "## Use the Model to Predict\n",
    "- on the Training set.\n",
    "- and the Test set."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d3af05f-246e-4de6-9bf9-61e5c086596d",
   "metadata": {},
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e67b7294-0edd-4c27-a2e9-48da15bcf575",
   "metadata": {},
   "source": [
    "## Round-up Scores"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0e105bc-c59c-4a57-a004-c2eb30801851",
   "metadata": {},
   "source": [
    "scores = {\n",
    "    'accuracy': {'train': accuracy_score(y_train, train_preds), 'test': accuracy_score(y_test, test_preds)},\n",
    "    'precision': {'train': precision_score(y_train, train_preds), 'test': precision_score(y_test, test_preds)},\n",
    "    'recall': {'train': recall_score(y_train, train_preds), 'test': recall_score(y_test, test_preds)},\n",
    "    'f1-score': {'train': f1_score(y_train, train_preds), 'test': f1_score(y_test, test_preds)},\n",
    "}\n",
    "print(scores)\n",
    "print(y_test.head())\n",
    "print(test_preds[0:5])\n",
    "scores_df = pd.DataFrame(scores)\n",
    "print(scores_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc1f6f42-9322-4204-96d6-6fa4a99ee02b",
   "metadata": {},
   "source": [
    "## Questions\n",
    "- What the problem is about?\n",
    "    - Binary classification of the coronavirus based on a kaggle dataset.\n",
    "- What prior knowledge the agent has, which influences the model it builds?\n",
    "    - None.\n",
    "- What data and feedback on the data is available?\n",
    "    - Symptoms, age, sex, diagnosis\n",
    "- What is the size of the data?\n",
    "    - (278848, 11)\n",
    "- How to load a dataset that has non-numbers?\n",
    "    - Handled in section #Numerify Remaining Data above.\n",
    "- What are the features (predictors and target variable) in the data?\n",
    "    - Predictors: symptoms\n",
    "    - Target: diagnosis\n",
    "- Are there any missing data? If so, how to handle them?\n",
    "    - Yes. Handled in #Remove Bad Data and #Numerify Remaining Data above.\n",
    "- what the data is saying?\n",
    "    - Shown by the heatmap.\n",
    "- what kind of model(learning agent) is suited for the data?\n",
    "    - Possibly a deep learning model would fit such messy data better.\n",
    "- are all predictors necessary for the agent?\n",
    "    - No, but we'll take what we can get.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "22bc9d10-3c92-4ce9-816b-ba1657692221",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ai",
   "language": "python",
   "name": "venv-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
